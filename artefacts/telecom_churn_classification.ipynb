{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∏ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –≤ mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í —Ä–∞–º–∫–∞—Ö –¥–∞–Ω–Ω–æ–≥–æ –Ω–æ—É—Ç–±—É–∫–∞ –º—ã –ø—Ä–æ–≤–µ–¥–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –ø–æ –ø—Ä–æ–≥–Ω–æ–∑—É –æ—Ç—Ç–æ–∫–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤. –í—ã–ø–æ–ª–Ω–∏–º —Å–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:\n",
    "* –ø–æ–¥–≥—Ä—É–∑–∏–º –¥–∞–Ω–Ω—ã–µ \n",
    "* –∑–∞–ø—É—Å—Ç–∏–º –æ–±—É—á–µ–Ω–∏–µ –∏ –ø–æ–∏—Å–∫ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ –≤ —Ä–∞–º–∫–∞—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\n",
    "* –∑–∞–ª–æ–≥–≥–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏ –∏ –º–µ—Ç—Ä–∏–∫–∏ –≤ mlflow\n",
    "* —Å–æ—Ö—Ä–∞–Ω–∏–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –≤ s3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ s3\n",
    "–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —è –ø–æ–¥–≥—Ä—É–∑–∏–ª .csv —Ñ–∞–π–ª –≤ —Å–≤–æ–π s3 –±–∞–∫–µ—Ç. –ü–æ–ª—É—á–∏–º –µ–≥–æ –æ—Ç—Ç—É–¥–∞. –î–æ—Å—Ç—É–ø –∫ s3 —è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é –≤ dockerfile.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.store.artifact.artifact_repository_registry import get_artifact_repository\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import (GridSearchCV, StratifiedKFold,\n",
    "                                     cross_val_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/telecom_churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Account length</th>\n",
       "      <th>Area code</th>\n",
       "      <th>International plan</th>\n",
       "      <th>Voice mail plan</th>\n",
       "      <th>Number vmail messages</th>\n",
       "      <th>Total day minutes</th>\n",
       "      <th>Total day calls</th>\n",
       "      <th>Total day charge</th>\n",
       "      <th>Total eve minutes</th>\n",
       "      <th>Total eve calls</th>\n",
       "      <th>Total eve charge</th>\n",
       "      <th>Total night minutes</th>\n",
       "      <th>Total night calls</th>\n",
       "      <th>Total night charge</th>\n",
       "      <th>Total intl minutes</th>\n",
       "      <th>Total intl calls</th>\n",
       "      <th>Total intl charge</th>\n",
       "      <th>Customer service calls</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State  Account length  Area code International plan Voice mail plan  \\\n",
       "0    KS             128        415                 No             Yes   \n",
       "1    OH             107        415                 No             Yes   \n",
       "2    NJ             137        415                 No              No   \n",
       "3    OH              84        408                Yes              No   \n",
       "4    OK              75        415                Yes              No   \n",
       "\n",
       "   Number vmail messages  Total day minutes  Total day calls  \\\n",
       "0                     25              265.1              110   \n",
       "1                     26              161.6              123   \n",
       "2                      0              243.4              114   \n",
       "3                      0              299.4               71   \n",
       "4                      0              166.7              113   \n",
       "\n",
       "   Total day charge  Total eve minutes  Total eve calls  Total eve charge  \\\n",
       "0             45.07              197.4               99             16.78   \n",
       "1             27.47              195.5              103             16.62   \n",
       "2             41.38              121.2              110             10.30   \n",
       "3             50.90               61.9               88              5.26   \n",
       "4             28.34              148.3              122             12.61   \n",
       "\n",
       "   Total night minutes  Total night calls  Total night charge  \\\n",
       "0                244.7                 91               11.01   \n",
       "1                254.4                103               11.45   \n",
       "2                162.6                104                7.32   \n",
       "3                196.9                 89                8.86   \n",
       "4                186.9                121                8.41   \n",
       "\n",
       "   Total intl minutes  Total intl calls  Total intl charge  \\\n",
       "0                10.0                 3               2.70   \n",
       "1                13.7                 3               3.70   \n",
       "2                12.2                 5               3.29   \n",
       "3                 6.6                 7               1.78   \n",
       "4                10.1                 3               2.73   \n",
       "\n",
       "   Customer service calls  Churn  \n",
       "0                       1  False  \n",
       "1                       1  False  \n",
       "2                       0  False  \n",
       "3                       2  False  \n",
       "4                       3  False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3333, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3333 entries, 0 to 3332\n",
      "Data columns (total 20 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   State                   3333 non-null   object \n",
      " 1   Account length          3333 non-null   int64  \n",
      " 2   Area code               3333 non-null   int64  \n",
      " 3   International plan      3333 non-null   object \n",
      " 4   Voice mail plan         3333 non-null   object \n",
      " 5   Number vmail messages   3333 non-null   int64  \n",
      " 6   Total day minutes       3333 non-null   float64\n",
      " 7   Total day calls         3333 non-null   int64  \n",
      " 8   Total day charge        3333 non-null   float64\n",
      " 9   Total eve minutes       3333 non-null   float64\n",
      " 10  Total eve calls         3333 non-null   int64  \n",
      " 11  Total eve charge        3333 non-null   float64\n",
      " 12  Total night minutes     3333 non-null   float64\n",
      " 13  Total night calls       3333 non-null   int64  \n",
      " 14  Total night charge      3333 non-null   float64\n",
      " 15  Total intl minutes      3333 non-null   float64\n",
      " 16  Total intl calls        3333 non-null   int64  \n",
      " 17  Total intl charge       3333 non-null   float64\n",
      " 18  Customer service calls  3333 non-null   int64  \n",
      " 19  Churn                   3333 non-null   bool   \n",
      "dtypes: bool(1), float64(8), int64(8), object(3)\n",
      "memory usage: 498.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞–±–æ—Ä –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∏–∑ —Å–µ–±—è 3333 –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∫–æ–º–ø–∞–Ω–∏–∏ —Ç–µ–ª–µ—Ñ–æ–Ω–Ω–æ–π —Å–≤—è–∑–∏. –ò–º–µ–µ—Ç—Å—è 19 —Ñ–∏—á–µ–π, –∞ –∫–æ–ª–æ–Ω–∫–∞ Churn –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∏–∑ —Å–µ–±—è –±—É–ª–µ–≤—ã –∑–Ω–∞—á–µ–Ω–∏—è, –≥–¥–µ 0 - –∞–±–æ–Ω–µ–Ω—Ç –ª–æ—è–ª–µ–Ω, 1 - –∞–±–æ–Ω–µ–Ω—Ç –ø–æ–º–µ–Ω—è–ª —Ç–∞—Ä–∏—Ñ (—É—à–µ–ª). –ú—ã —Ö–æ—Ç–∏–º –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞—Ç—å —É—à–µ–ª –ª–∏ –∫–ª–∏–µ–Ω—Ç (–æ—Ç—Ç–æ–∫).\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Account length',\n",
       "  'Area code',\n",
       "  'Number vmail messages',\n",
       "  'Total day minutes',\n",
       "  'Total day calls',\n",
       "  'Total day charge',\n",
       "  'Total eve minutes',\n",
       "  'Total eve calls',\n",
       "  'Total eve charge',\n",
       "  'Total night minutes',\n",
       "  'Total night calls',\n",
       "  'Total night charge',\n",
       "  'Total intl minutes',\n",
       "  'Total intl calls',\n",
       "  'Total intl charge',\n",
       "  'Customer service calls'],\n",
       " 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –û–±—É—á–∏–º –º–æ–¥–µ–ª—å –Ω–∞ —á–∏—Å–ª–µ–Ω–Ω—ã—Ö —Ñ–∏—á–∞—Ö\n",
    "cols = []\n",
    "for i in df.columns:\n",
    "    if (df[i].dtype == \"float64\") or (df[i].dtype == 'int64'):\n",
    "        cols.append(i)\n",
    "\n",
    "cols, len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy score: 92.50%\n"
     ]
    }
   ],
   "source": [
    "# Divide the dataset into the input and target\n",
    "X, y = df[cols].copy(), np.asarray(df[\"Churn\"],dtype='int8')\n",
    "\n",
    "# Initialize a stratified split of our dataset for the validation process\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize the classifier with the default parameters \n",
    "rfc = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Train it on the training set\n",
    "results = cross_val_score(rfc, X, y, cv=skf)\n",
    "\n",
    "# Evaluate the accuracy on the test set\n",
    "print(\"CV accuracy score: {:.2f}%\".format(results.mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò—Å–ø–æ–ª—å–∑—É–µ–º —ç—Ç—É –º–æ–¥–µ–ª—å –∫–∞–∫ –±–µ–π–∑–ª–∞–π–Ω –∏ –ø–æ–ø—Ä–æ–±—É–µ–º —É–≤–µ–ª–∏—á–∏—Ç—å score —Å –ø–æ–º–æ—â—å—é –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–π –∏ GridSearch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û–±—É—á–µ–Ω–∏–µ –∏ –ø–æ–∏—Å–∫ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–ø—Ä–æ–±—É–µ–º –æ–±—É—á–∏—Ç—å RandomForest, SVC, LogRegression –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'gradien_boosting': {\n",
    "        'model' : GradientBoostingClassifier(),\n",
    "        'params' : {\n",
    "            'n_estimators' : range(10, 50, 10),\n",
    "            'max_depth': range(5,9,1),\n",
    "            'max_features':range(7,20,3)         \n",
    "        }\n",
    "    },\n",
    "    'random_forest' : {\n",
    "        'model' : RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'n_estimators' : range(10, 50, 10),\n",
    "            'max_features': range(3, 15, 3),\n",
    "            'max_depth': [5, 10, 15, 20],\n",
    "            'min_samples_leaf': [1, 3, 5, 7],   \n",
    "              \n",
    "              }\n",
    "    },\n",
    "    'log_reg' : {\n",
    "        'model' : LogisticRegression(),\n",
    "        'params' : {\n",
    "            'C' : [1, 2, 5]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://kirillbucket/mlflow/344457750143816081', creation_time=1732301882313, experiment_id='344457750143816081', last_update_time=1732301882313, lifecycle_stage='active', name='telecom_churn_classification_test', tags={}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç\n",
    "exp_name = \"telecom_churn_classification_test\"\n",
    "experiment_id='344457750143816081'\n",
    "#experiment_id = mlflow.create_experiment(exp_name)\n",
    "mlflow.set_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a4c240a28740699bf0c6a0c6c66aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2024/11/22 20:21:30 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "2024/11/22 20:21:30 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "2024/11/22 20:21:30 WARNING mlflow.models.evaluation.default_evaluator: Computing sklearn model score failed: TypeError(\"BaseSearchCV.score() got an unexpected keyword argument 'sample_weight'\"). Set logging level to DEBUG to see the full traceback.\n",
      "2024/11/22 20:21:31 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "2024/11/22 20:21:35 WARNING mlflow.models.evaluation.default_evaluator: SHAP or matplotlib package is not installed, so model explainability insights will not be logged.\n",
      "2024/11/22 20:21:35 INFO mlflow.tracking._tracking_service.client: üèÉ View run gradien_boosting at: http://mlflow-service:5000/#/experiments/344457750143816081/runs/fd9bc3513c0449ebaf8d2796a471a40d.\n",
      "2024/11/22 20:21:35 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://mlflow-service:5000/#/experiments/344457750143816081.\n",
      "/opt/conda/lib/python3.11/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20ee32f243d49fd8ead65ee062f3e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2024/11/22 20:40:28 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "2024/11/22 20:40:28 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "2024/11/22 20:40:28 WARNING mlflow.models.evaluation.default_evaluator: Computing sklearn model score failed: TypeError(\"BaseSearchCV.score() got an unexpected keyword argument 'sample_weight'\"). Set logging level to DEBUG to see the full traceback.\n",
      "2024/11/22 20:40:28 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "2024/11/22 20:40:42 WARNING mlflow.models.evaluation.default_evaluator: SHAP or matplotlib package is not installed, so model explainability insights will not be logged.\n",
      "2024/11/22 20:40:42 INFO mlflow.tracking._tracking_service.client: üèÉ View run random_forest at: http://mlflow-service:5000/#/experiments/344457750143816081/runs/231962c89d9a48b8933071b9387ea3b1.\n",
      "2024/11/22 20:40:42 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://mlflow-service:5000/#/experiments/344457750143816081.\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.11/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad33c5a35ec84bb484a2ede72b303af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/mlflow/types/utils.py:406: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2024/11/22 20:41:31 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "2024/11/22 20:41:31 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "2024/11/22 20:41:31 WARNING mlflow.models.evaluation.default_evaluator: Computing sklearn model score failed: TypeError(\"BaseSearchCV.score() got an unexpected keyword argument 'sample_weight'\"). Set logging level to DEBUG to see the full traceback.\n",
      "2024/11/22 20:41:32 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "2024/11/22 20:41:43 WARNING mlflow.models.evaluation.default_evaluator: SHAP or matplotlib package is not installed, so model explainability insights will not be logged.\n",
      "2024/11/22 20:41:43 INFO mlflow.tracking._tracking_service.client: üèÉ View run log_reg at: http://mlflow-service:5000/#/experiments/344457750143816081/runs/34433e923d4b45cf94e1b706bb4dfb0f.\n",
      "2024/11/22 20:41:43 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://mlflow-service:5000/#/experiments/344457750143816081.\n",
      "2024/11/22 20:41:43 INFO mlflow.tracking._tracking_service.client: üèÉ View run parent_run at: http://mlflow-service:5000/#/experiments/344457750143816081/runs/b0f0235330814638b7927a8dba37b1b1.\n",
      "2024/11/22 20:41:43 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://mlflow-service:5000/#/experiments/344457750143816081.\n"
     ]
    }
   ],
   "source": [
    "X, y = df[cols].copy(), np.asarray(df[\"Churn\"],dtype='int8')\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5,  random_state=42)\n",
    "\n",
    "scores = []\n",
    "with mlflow.start_run(run_name=\"parent_run\", experiment_id = experiment_id, description = \"parent\") as parent_run:\n",
    "    for model_name, mp in model_params.items():\n",
    "        with mlflow.start_run(run_name=model_name, experiment_id=experiment_id, nested=True) as child_run:\n",
    "            grid_search = GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False) \n",
    "            # Train it on the training set# Fit the grid search to the data\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            \n",
    "            # Evaluate the best model on the test set\n",
    "            y_pred = grid_search.predict(X_test)\n",
    "            scores.append({\n",
    "                'model' : model_name,\n",
    "                'top_score' : grid_search.best_score_,\n",
    "                'best_params' : grid_search.best_params_})\n",
    "\n",
    "            # –°–æ–∑–¥–∞–¥–∏–º –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç.\n",
    "            eval_df = X_val.copy()\n",
    "            eval_df[\"churn\"] = y_val\n",
    "        \n",
    "            # –°–æ—Ö—Ä–∞–Ω–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é MLFlow.\n",
    "            signature = infer_signature(X_test, y_pred)\n",
    "            model_info = mlflow.sklearn.log_model(grid_search, \"classification_model\", signature=signature)\n",
    "            mlflow.evaluate(\n",
    "                model=model_info.model_uri,\n",
    "                data=eval_df,\n",
    "                targets=\"churn\",\n",
    "                model_type=\"classifier\",\n",
    "                evaluators=[\"default\"],\n",
    "            )\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>top_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gradien_boosting</td>\n",
       "      <td>0.924985</td>\n",
       "      <td>{'max_depth': 7, 'max_features': 7, 'n_estimat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.924611</td>\n",
       "      <td>{'max_depth': 15, 'max_features': 12, 'min_sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_reg</td>\n",
       "      <td>0.855965</td>\n",
       "      <td>{'C': 2}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model  top_score  \\\n",
       "0  gradien_boosting   0.924985   \n",
       "1     random_forest   0.924611   \n",
       "2           log_reg   0.855965   \n",
       "\n",
       "                                         best_params  \n",
       "0  {'max_depth': 7, 'max_features': 7, 'n_estimat...  \n",
       "1  {'max_depth': 15, 'max_features': 12, 'min_sam...  \n",
       "2                                           {'C': 2}  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores = pd.DataFrame(scores)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–° –ø–æ–º–æ—â—å—é GridSearchCV —É–¥–∞–ª–æ—Å—å —É–≤–µ–ª–∏—á–∏—Ç—å —Å–∫–æ—Ä –º–æ–¥–µ–ª–∏. –ú–µ—Ç—Ä–∏–∫–∏, –¥–∞—Ç–∞—Å–µ—Ç, –º–æ–¥–µ–ª—å –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω—ã –∏ –∑–∞—Ä–µ–≥–∏—Å—Ç–∏—Ä–æ–≤–∞–Ω—ã –∏ –º—ã –º–æ–∂–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∞—à—É –º–æ–¥–µ–ª—å –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
